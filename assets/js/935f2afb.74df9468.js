"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Start Locally","href":"/torchsite/docs/intro","docId":"intro"},{"type":"category","label":"Mobile","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"PyTorch Mobile","href":"/torchsite/docs/Mobile/intro","docId":"Mobile/intro"}],"href":"/torchsite/docs/category/mobile"},{"type":"category","label":"Ecosystem","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Ecosystem Tools","href":"/torchsite/docs/ecosystem/intro","docId":"ecosystem/intro"}],"href":"/torchsite/docs/category/ecosystem"},{"type":"category","label":"Resources","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Resources","href":"/torchsite/docs/Resources/intro","docId":"Resources/intro"}],"href":"/torchsite/docs/category/resources"}]},"docs":{"ecosystem/intro":{"id":"ecosystem/intro","title":"Ecosystem Tools","description":"Tap into a rich ecosystem of tools, libraries, and more to support, accelerate, and explore AI development.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Start Locally","description":"Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. This should be suitable for many users. Preview is available if you want the latest, not fully tested and supported, builds that are generated nightly. Please ensure that you have met the prerequisites below (e.g., numpy), depending on your package manager. Anaconda is our recommended package manager since it installs all dependencies. You can also install previous versions of PyTorch. Note that LibTorch is only available for C++.","sidebar":"tutorialSidebar"},"Mobile/intro":{"id":"Mobile/intro","title":"PyTorch Mobile","description":"There is a growing need to execute ML models on edge devices to reduce latency, preserve privacy, and enable new interactive use cases.","sidebar":"tutorialSidebar"},"Resources/intro":{"id":"Resources/intro","title":"Resources","description":"Explore educational courses, get your questions answered, and join the discussion with other PyTorch developers.","sidebar":"tutorialSidebar"}}}')}}]);